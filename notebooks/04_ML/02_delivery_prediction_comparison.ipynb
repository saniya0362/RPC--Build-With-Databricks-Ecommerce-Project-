{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6b92adf-3b29-42cf-9204-d7f54cd513e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cf794f1-72a2-4648-944b-0d94bef66d04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "718fcbe8-ddf2-44fc-89f4-426c624d704e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Read fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03f9bac8-1e2b-47ed-a2ce-4c3a6fabfbc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fact_orders_df = spark.table(\"olist_ecommerce.gold.fact_orders\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0876e22-eea5-4512-b0b7-8db4fb7beddb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Select features & target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9828ecd-fe9d-424d-bfef-09bb13713971",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"order_value\",\n",
    "    \"total_freight\",\n",
    "    \"total_items\",\n",
    "    \"approval_delay_hours\",\n",
    "    \"estimated_delivery_days\",\n",
    "    \"installments_count\"\n",
    "]\n",
    "\n",
    "TARGET = \"is_late_delivery\"\n",
    "\n",
    "df = fact_orders_df.dropna(subset=FEATURES + [TARGET])\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01433fde-1ca9-47b2-9e9b-610ec0e3330f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34d0c5b3-6044-4c4e-8fdc-f855bdd4ed4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54444e09-1756-4a43-88b2-cc7ad9972cd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daf8ce31-e6e2-4207-abc6-dfb150d47c08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"logistic_regression\": LogisticRegression(max_iter=500, class_weight=\"balanced\"),\n",
    "    \"decision_tree\": DecisionTreeClassifier(max_depth=8,class_weight=\"balanced\"),\n",
    "    \"random_forest\": RandomForestClassifier(n_estimators=200,max_depth=10,random_state=42,class_weight=\"balanced\")\n",
    "    }\n",
    "\n",
    "THRESHOLD = 0.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c33b93d-05fe-4f0c-867f-cc1dc5b52b20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Train, Evaluate, Log to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6d5a922-57f5-4092-bce1-c798c6c55ff0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression → AUC: 0.581, F1: 0.150\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree → AUC: 0.629, F1: 0.163\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest → AUC: 0.640, F1: 0.166\n"
     ]
    }
   ],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "mlflow.set_experiment(\"/delivery_prediction_model_comparison\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"delivery_{name}\"):\n",
    "\n",
    "        mlflow.log_param(\"model_type\", name)\n",
    "        mlflow.log_param(\"threshold\", float(THRESHOLD))\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        probs = model.predict_proba(X_test)[:, 1]\n",
    "        preds = (probs >= THRESHOLD).astype(int)\n",
    "\n",
    "        auc = roc_auc_score(y_test, probs)\n",
    "        f1 = f1_score(y_test, preds)\n",
    "\n",
    "        mlflow.log_metric(\"auc\", auc)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        input_example = X_train.iloc[:5]\n",
    "        output_example = model.predict_proba(input_example)\n",
    "        signature = infer_signature(input_example, output_example)\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=\"model\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "\n",
    "        results.append({\n",
    "            \"model\": name,\n",
    "            \"auc\": auc,\n",
    "            \"f1\": f1,\n",
    "            \"run_id\": mlflow.active_run().info.run_id\n",
    "        })\n",
    "\n",
    "        print(f\"{name} → AUC: {auc:.3f}, F1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97feeb4b-4f50-46b3-a3c6-6f88120b4142",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Decide Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19f8509e-644d-43f7-9f95-7e13ca128874",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save predictions to Gold"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.640072</td>\n",
       "      <td>0.165695</td>\n",
       "      <td>0325bc1675d0486f89fb1a0547691f1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.629311</td>\n",
       "      <td>0.163424</td>\n",
       "      <td>49b8ad65cae74e0c95f50368ed465134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.580740</td>\n",
       "      <td>0.149610</td>\n",
       "      <td>fb37fd6bcb0f4a7a99594539aa5edd49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model       auc        f1                            run_id\n",
       "2        random_forest  0.640072  0.165695  0325bc1675d0486f89fb1a0547691f1f\n",
       "1        decision_tree  0.629311  0.163424  49b8ad65cae74e0c95f50368ed465134\n",
       "0  logistic_regression  0.580740  0.149610  fb37fd6bcb0f4a7a99594539aa5edd49"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(by=\"f1\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_delivery_prediction_comparison",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}